# Оптимизация взаимодействия с БД

## User story

Тут должны быть описаны пльзовательские истории, которые определят целевые 
значения метрик, но так как их нет, то я их придумаю.

### Импорт данных

Для проведения нагрузочного тестирования на тестовом стенде необходимо регулярно
импортировать различные наборы данных о расписании автобусов из больших
текстовых файлов, файлы получаются из внешних систем поэтому нет возможности
осуществлять накат предварительно сформированного sql-дампа.
Текущее решение не позволяет выполять эту операцию быстро из-за чего подготовка
тестовой среды происходит непозволительно долгое время чем блокирует всю
дальнейшую работу пайплайна.

### Отображение расписания

Система веб-аналитики показывает, что при просмотре расписаний на популярных
направлениях пользователи не дожидаются загрузки страницы и уходят с сайта.
Британские учёные доказали, что финансово успешные web-проекты должны
формировать основной документ страницы не больше чем за 300 милисекунд.

## Что сделать

* Нужно оптимизировать механизм перезагрузки расписания из файла так, 
  * файл large.json в пределах минуты.
* Необходимо ускорить отображение расписаний
  * страница автобусы/Самара/Москва должна открываться за адекватное время

# Оптимизация импорта

## Основные инструменты для исследования

* perfolab (чуть доведенный до ума фреймворк разработанный мной в рамках предыдущего задания)
* stackprof
* speedscope

## Основные проблемы на начальном этапе

* Отсутствие тестов.
  * Нет возможности проводить оптимизацию без опасения что-либо сломать.
* Вся процедура выполняется в едином блоке кода без разбивки на методы.
  * Сложно выяснить что именно вызывает основные проблемы.

## Первичный анализ

Замеры времени импорта показывют что оно равстёт приблизительно линейно в
зависимости от размера файла, что несложно увидеть и при обычном чтении
оригинального скрипта. Инструменты показывают что большую часть времени
выполняются запросы на поиск и создание объектов.

Уже на данном этапе очевидно что необходимо кардинально уменьшать количество
отправляемых в БД запросов. Внимательное изучение скрипт показывает что
от запросов на поиск данных в бд можно полностью избавиться, так как изначально
в БД нет никаких данных. Уменьшения же количества запросов на вставку данных
можно с помощью массового создания объектов.

Для удобства можно воспользоваться библиотекой activerecord-import.

## Первые шаги

* Код импорта был выделен в отдельный класс для удобства анализа и тестрования.
* Был написан минимальный тест на корректнось работы скрипта.
* Произведен первичный анализ скрипта на файле small.json

|            benchmark           | Previous | Current |      Diff %     |
|--------------------------------|----------|---------|-----------------|
| total                          |          | 3014ms  |                 |

## Выделение методов

Хоть у нас и есть инсайдерская информация о частоте появления уникальных записей
различных моделей, всё же будет намного удобнее ориентироваться в результатах
профилировщиков если выделить создание разных объектов в отельные методы.
Как и ожидалось, выделение методов не оказало значительного влияния на время
работы импорта.

|            benchmark           | Previous  | Current |      Diff %    |
|--------------------------------|-----------|---------|----------------|
| total                          | 3014ms    | 2976ms  | -1%            |

Кроме того сразу видно что 59% времени уходит на создание и обновление записей
об автобусах.

## Оптимизация создания автобусов

При внимательном изучении механизма создания автобусов становится очевидным
что выполняются множество лишних действий:
* лишнее обновление записи, имя модели выставляется уже после создания;
* обновление модели и услуг происходит каждый раз, даже если автобус уже есть в БД;
* поиск автобусов в БД, хотя их создание происходило в этом же скрипте;

|            benchmark           | Previous | Current |      Diff %     |
|--------------------------------|----------|---------|-----------------|
| total                          | 2976ms   | 2628ms  | -11%            |

## Оптимизация выставления связей между автобусами и услугами

Результат улучшения оказался не столь существенным для файла small.json,
на обновление данных об услугах в автобусах всё ещё уходит около 45% времени,
это говорит о том что нужно обтимизировать выставление связей между автобусами
и услугами.
Оптимизировать это можно несколькими способами, но самым эффективным будет
массовое выставление связей уже после создания записей автобусов.

|            benchmark           | Previous | Current  |      Diff %     |
|--------------------------------|----------|----------|-----------------|
| total                          | 2628ms   | 1450ms   | -44%            |

## Создание услуг

На поиск и создание услуг уходит 34% времени. При этом заранее известно что
услуг ровно 10 (валидация на имя в модели и подсказка в Readme.md)
Вместо того чтобы осуществлять поиск и создание можно было бы заранее создать
все 10 записей игнорируя данные из json. Но так как у нас есть требование на
полное отсутствие функциональных изменений, то отказываемся от этой идеи, так
как для файла example.json должно быть создано только 3 услуги.
Так или иначе можно избавиться от необходимости поиска записей в БД.

|            benchmark           | Previous | Current  |      Diff %     |
|--------------------------------|----------|----------|-----------------|
| total                          | 1450ms   | 885ms    | -38%            |

## Импорт расписаний

Наконец дошли до основной модели. Замеры показывают что 39% времени уходит на
создание записей модели Trip.
Так же как и с привязкой услуг к автобусам используем массовый импорт заранее
подготовленных данных.

|            benchmark           | Previous | Current  |      Diff %     |
|--------------------------------|----------|----------|-----------------|
| total                          | 885ms    | 626ms    | -29%            |

## Оптимизация создания городов

Теперь 38% времени уходит на создание записей модели City. Так же как и ранее
убираем поиск сохраненных записей в БД.

|            benchmark           | Previous | Current  |      Diff %     |
|--------------------------------|----------|----------|-----------------|
| total                          | 626ms    | 357ms    | -43%            |

## Предварительные итоги

Проверка иморта файла large.json показала что время импорта составляет около
12 секунд, что уже существенно ниже исходных требований, но скрипт всё ещё
можно оптимизировать без особых сложностей.
На файле small.json stackprof показывает что около 50% времени уходит на
создание записей модели автобуса, однако на файлах medium.json и large.json
на данное действие уходит намного меньше времени в процентном отношении (24%
и 3,5% соответственно).

На больших файла на первый план выходит уже работа массового импорта записей.
Причём много времени уходит на валидации записей.
Можно было бы отключить их, но строго говоря это действие является
функциональным изменением, так как оригинальный скрипт просто бы пропустил
навалидные записи.

Дальнейший анализ будет производиться на файле medium.json, но уже после
выполнения второй части задания. Вероятно решение второй части зададания 
несколько замедлит работу импорта, так как наверняка в рамках изменений 
потребуется добавить индексы, что должно несколько замедлить добавление записей.

# Ускорение отображения расписаний

## Основные инструменты для исследования

* rails log
* rack-mini-profiler

## Первичный анализ

Страница расписания рейсов из Самары в Москву генерируется около 2 секунд
в dev-окружении и около 1,2 секунды в production окружении.
При этом время на работу с БД относительно небольшое:
Production: Views: 934.6ms | ActiveRecord: 356.4ms
Development: Views: 1714.1ms | ActiveRecord: 242.4ms.
Вызывает вопросы почему время на ActiveRecord в Development-окружении
отображается как меньшее, пока решил отложить этот вопрос.
Очевидно тут стоило бы заняться в первую очередь вопросом генерации вьюх,
но так как тема задания касается оптимизации БД, то пока проигнорируем это.

## Анализ с использованием rack-mini-profiler

Для удобства решил выполнять основную работу по оптимизации в development.
Подключение rack-mini-profiler сразу же ухудшило показатели
Views: 5273.9ms | ActiveRecord: 737.0ms, тем не менее общая картина должна
быть той же.

## Двойная проблема N+1 (автобусы и сервисы)

Даже без установки bullet в логе видно огромное количество однотипных запросов.
Добавил preload на обе модели.
Время генерации страницы сократилось вдвое, при этом на работу ActiveRecord
теперь уходит всего 22ms (если верить логу rails)
Views: 2928.7ms | ActiveRecord: 22.0ms.
Предполагаю что уменьшение времени на вьюхи обусловлено меньшим временем для
формирования отчёта rack-mini-profiler.
С отключенным rack-mini-profiler:
Production: Views: 345.8ms | ActiveRecord: 22.2ms
Development: Views: 984.0ms | ActiveRecord: 17.3ms

## Оптимизация рендеринга

Как бы ни хотелось продолжить, но в дальнейшей оптимизации запросов не вижу
смысла, можно было бы еще добавить добавить индекс на start_time таблицы trips,
но это ускорило бы и без того быстрый запрос (на моём ноутбуке этот запрос
выполняется за 3мс) и в любом случае это не позволит добиться придуманного мной
целевого показателя.

Поэтому единственным способом достижения цели является оптимизация реднеринга.
Используя механизм render collection удалось добиться формирования страницы
в production окружении в пределах 150-200 мс без использования кэширования,
что соответствует целевым показателям.

# Оптимизация импорта: империя наносит ответный удар

Снова придумываю пользовательскую историю.
Отдел продаж начал продавать функционалость позволяющую провести миграцию
с системы конкурентов.

Объем данных в исходной системе может быть произвольным.
Формат данных для импорта тот же и не может быть изменён.

## Что сделать

Нужно оптимизировать механизм загрузки данных из файла таким образом чтобы
потребление памяти не зависила от объёма данных.

## Общий план действий

Необходимо реализизовать потоковое чтение и импорт данных.
Основными проблемами является то что данные нужно импортировать в несколько
таблиц, нет возможности продолжительное время "накапливать" данные для
последующего импорта.
До начала работ по оптимизации желательно уточнить фунциональные требования:
* необходимось сохранения вызова валидаций при создании объектов;
* необходимость выполнения всех действий в рамках единой транзакции.

Для интереса я буду исходить из необходимости сохранения старого поведения,
поэтому вариант с импортом данных напрямую в PG из Readme.md будет
нецелесообразен, так как всё равно портребует создания объектов для запуска
валидаций.

Текущая идея состоит в том, чтобы при потоковом чтении из исходного файла
формировать буфер записей определённого размера с последующим импортом
с помощью activerecord-import.

## Потоковое чтение и импорт блоками

Для реализации потокового чтения была использована библиотека oj.
Благодаря использованию метода `Oj.sc_parse` и написанию простого
вспомогательного класса удалось сохранить код практически в неизменном виде.
Кроме того была использована встроенная библиотека zlib для возможности
поточного чтения из gz-файла, тем самым избавляя от необходимости распаковки
файлов большого размера.

Оверхед добавленный механизмом потокового чтения оказался незначительным.

|            benchmark           | Previous  | Current |      Diff %     |
|--------------------------------|-----------|---------|-----------------|
| total                          | 1498ms    | 1531ms  | 2%              |

## Оптимизация activerecord-import

Инструменты показывают что большую часть времени скрипт производит импорт данных
с помощью библиотеки activerecord-import.
К сожалению возможности настройки параметров иморта доволько ограничены.
Большая часть времени уходит на валидации, но, как было сказано ранее, от них я
отказываться не плананирую.
Можно было бы на время импорта отключить часть валидаций в тех случаях когда мы
заранее уверены в корректности данных, но этим мне уже заниматься довольно
лениво, к тому же это действие вряд ли бы дало больше 5 процентов уменшения
времени работы скрипта (валидации занимаю 17% от полного времени работы).

## Создание AR-объектов

На создание объектов уходит 20% времени. Существенного улучшения результатов
можно добиться только если произвести полный отказ от ActiveRecord,
а следовательно и от встроенных валидаций.
По примерной оценке такая работа могда бы уменьшить время работы импорта
на 60-70%, но данная работа сделала бы скрипт менее поддерживаемым из-за
расхождения валидаций в скрипте импорта и реальных моделей. Вынесение же
валидаций в отдельный модуль не выглядит целесообразным.