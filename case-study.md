# Case-study оптимизации

## Актуальная проблема

В нашем проекте возникли 2 серьёзных проблемы:
1) Необходимо было обработать файл с расписанием автобусов. У нас уже была программа на ruby, которая умела делать нужную обработку. Она успешно работала на файлах небольшого размера, но для большого файла она работала слишком долго.
2) Страница отображения расписания автобусов тоже работала слишком долго. Пользователи жаловались на долгую загрузку страницы (расписание Таганрог/Владивосток загружалось 42 секунды (~2к записей)).

Я решила исправить обе проблемы, оптимизировав загрузку и отображение.

## Оптимизация импорта данных

## Формирование метрики

Конечная метрика: время выполнения импорта файла `fixtures/large.json` должно укладываться в 60 сек.
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумала использовать такую метрику:
1) обработка файла после внесенных оптимизаций должна быть меньше, чем до оптимизации

## Предварительная подготовка

1) Добавила в проект тесты
2) Написала раннер для профилирования / мониторинга времени / памяти выполнения скрипта импорта

## Ваша находка №1
1) время выполнения fixtures/small.json - 10.167809
2) воспользуемся rbspy для профилирования скрипта импорта
3) rbspy / rubyprof выдают много лишних данных при вызове таски, поэтому можно вынести импорт в отдельный класс и профилировать его
4) вынесла в класс DataLoader, перенесла тесты

Пока выносила обратила внимание что файл считывается в память целиком, также в задании упоминается про файл 1М который весит примерно 3ГБ, перепишем сразу на стриминг
добавила класс JsonStreamer - собирает объекты и возвращает по одному. Гемы потоковой обработки выглядят сложновато для достаточно простой задачи, возможно они работают быстрее, но этим можно будет озаботиться попозже

## Ваша находка №2
1) время выполнения fixtures/small.json не поменялось - 10.473295
2) отчет stackfrof - главная точка роста:
в отчете видны 2 главные точки роста - update (41%) и find_or_create_by (25%)
3) что делать с update пока непонятно, а вот такое кол-во find_or_create_by можно заменить
4) Внесем правки в работу с городами, написано что в файле их не больше 100, попробуем собирать их в словарь, параллельно создавая
5) время выполнения fixtures/small.json - 8.523640
6) изменения в отчете профилировщика: find_or_create_by снизился до 18%

## Ваша находка №3
1) также у нас собирается еще 2 стравочника - services, buses
2) заменим find_or_create_by и там
3) services: 6.919434, find_or_create_by 23%
4) buses: 5.319638, find_or_create_by больше нет

## Ваша находка №4
1) отчет stackfrof - главная точка роста: update (64%)
2) обновляется автобус сервисами, это обновление в целом выглядит довольно бесполезно, потому что сервисы останутся от последнего trip в файле
3) поэтому обновление сервисами можно в принципе убрать, либо уточнить формат файла, должны ли они добавляться / обновляться или браться пересечение
4) убрали обновление заменив его на создание сервисов при создании автобуса (добавила модель buses_service)
5) время: 3.025756
6) отчет профилировщика: update больше нет

## Ваша находка №5
1) обратимся к логам и посмотрим на кол-во обращений к базе
2) на файл example (10 рейсов) к базе обращений было: 10 (создание trip) + 2 (проверка существования автобуса + создание) + 4 (проверка городов + создание) + 2 (создание сревисов) = 18
3) можно воспользоваться алгоритмом и стримингом из readme
4) время для small: 0.138599
5) medium: 0.510029
6) large: 3.958625
7) 1M: 38.381950
8) ну тут уже время упирается в стример, без каких либо преобразований он перебирает файл 1M за 34.973238
9) причем потребление памяти на 1М не превышает 8МБ
```
INITIAL MEMORY USAGE: 103 MB
MEMORY USAGE: 103 MB
MEMORY USAGE: 110 MB
... 7 строчек с 110 MB
MEMORY USAGE: 110 MB
MEMORY USAGE: 111 MB
... 26 строчек с 111 MB
MEMORY USAGE: 111 MB
FINAL MEMORY USAGE: 110 MB
```

## Оптимизация отображения расписания

## Формирование метрики

Конечная метрика: любая страница должна грузиться менее 0.3 секунды
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумала использовать такую метрику:
1) время рендеринга страницы после внесенных оптимизаций должно быть меньше, чем до оптимизации

## Оптимизация

Набор данных 1M. Для начала загрузим страницу http://localhost:3000/автобусы/Самара/Москва и посмотрим на логи

## Ваша находка №1
1) Completed 200 OK in 745ms (Views: 228.0ms | ActiveRecord: 487.9ms (120 queries, 0 cached) | GC: 33.0ms)
2) Выборка занимает бОльшую часть времени, начнем с нее. Также по логам видно, что для каждого trip делается отдельный запрос к базе чтобы достать автобус, а для него сервисы
3) Попробуем воспользоваться preload
4) Completed 200 OK in 157ms (Views: 55.8ms | ActiveRecord: 97.3ms (7 queries, 0 cached) | GC: 6.0ms)
5) Время загрузки уменьшилось и кол-во запросов тоже
6) Рендер тоже ускорился, потому что все вызовы были непосредствено из вьюхи

## Ваша находка №2
1) Оптимизируем рендеринг (огромное кол-во рендеров)
2) Сделаем рендер коллекции сервисов
3) Completed 200 OK in 157ms (Views: 52.2ms | ActiveRecord: 92.7ms (7 queries, 0 cached) | GC: 4.5ms)

## Ваша находка №3
1) Оптимизируем рендеринг дальше, сделаем рендер коллекции рейсов
2) Completed 200 OK in 153ms (Views: 56.9ms | ActiveRecord: 92.2ms (7 queries, 0 cached) | GC: 1.0ms)
3) В пределах погрешности ничего не поменялось, но все еще отдельно рендерятся delimeter / services

## Ваша находка №4
1) Посмотрим на rack-mini-profiler
2) Больше всего времени уходит на запрос SELECT COUNT(*) FROM "trips" WHERE "trips"."from_id" = $1 AND "trips"."to_id" = $2; (126 ms)
3) Посмотрим на план запроса:
  Gather  (cost=1000.00..24758.70 rows=87 width=34)
    Workers Planned: 2
    ->  Parallel Seq Scan on trips  (cost=0.00..23750.00 rows=36 width=34)
    Filter: ((from_id = 10) AND (to_id = 92))
    (4 rows)
4) Избавимся от Seq Scan добавив составной индекс. Так как поиск идет всегда по (from_id, to_id). Также сделаем сразу сортированный индекс по времени
5) План запроса после добавления индекса:
  Bitmap Heap Scan on trips  (cost=13.75..3377.62 rows=909 width=34)
   Recheck Cond: ((from_id = 10) AND (to_id = 92))
   ->  Bitmap Index Scan on index_trips_on_from_id_and_to_id  (cost=0.00..13.53 rows=909 width=0)
   Index Cond: ((from_id = 10) AND (to_id = 92))
   (4 rows)
6) Теперь запрос не является главной точкой роста (2.1 ms)

## Ваша находка №5
1) Зальем 10М (~6 минут) и проверим на более объемных данных
2) Расписание Самара/Москва (511 рейсов): Completed 200 OK in 342ms (Views: 321.6ms | ActiveRecord: 15.2ms (7 queries, 0 cached) | GC: 41.2ms)
3) Главной точкой роста опять стал рендеринг, попробуем оптимизировать его еще лучше
4) Попробуем убрать отдельный рендер разделителя и сервисов
5) Воспользовалась spacer_template: Completed 200 OK in 276ms (Views: 217.5ms | ActiveRecord: 51.2ms (7 queries, 0 cached) | GC: 11.7ms)
6) Уберем рендер сервисов в partial trip. некрасиво, но это ускорит рендер
7) Completed 200 OK in 104ms (Views: 85.7ms | ActiveRecord: 14.4ms (7 queries, 0 cached) | GC: 5.2ms)

## Ваша находка №6
1) Проверим на большем кол-ве
2) самое большое кол-во рейсов - 4191 (Таганрог - Таганрог)
3) Completed 200 OK in 620ms (Views: 499.6ms | ActiveRecord: 127.1ms (7 queries, 1 cached) | GC: 55.3ms)
4) Время почти в 2 раза больше желательного
5) Посмотрим на это со стороны того, что за раз пользователю не надо видеть все 4к записей, можно добавить пагинацию
6) добавила пагинацию с дефолтным значением 100 записей (гем использовать не стала, потому что в текущем варианте это не сложно сделать)
7) одна страница: Completed 200 OK in 39ms (Views: 23.5ms | ActiveRecord: 10.0ms (7 queries, 0 cached) | GC: 0.0ms)

Можно закончить оптимизацию на этом, так как время выполнения укладывается в приемлемые рамки

Для красоты конечно лучше бы добавить турбо фреймы, чтобы полностью не перезагружать страницу при пагинации, но это уже не входят в текущую задачу

## Результаты
В результате проделанной оптимизации удалось ускорить импорт файла `fixtures/large.json` до 4 секунд и уложиться в метрику. Также удалось ускорить загрузку страницы Таганрог/Владивосток до ~300ms без пагинации, или ~50ms с пагинацией по 100 рейсов на странице

## Защита от регрессии производительности
1) для импорта данных был написан тест на проверку времени выполнения
2) для отображения расписания был бы написан тест на N+1 запрос, если бы rspec-sqlimit был совместим с rails 8.0.1
