# Актуальная проблема
## В проекте возникли две ключевые проблемы производительности:

Медленный импорт данных из JSON файлов в базу данных. Текущая наивная реализация не способна обработать large.json (100K записей) за приемлемое время.

Неэффективное отображение расписания автобусов на странице, что приводит к значительным задержкам при увеличении объема данных.

## Формирование метрик
Для оценки эффективности оптимизации определены следующие метрики:

Для импорта данных:
Время выполнения импорта large.json (целевое значение - менее 1 минуты)
Потребление памяти во время импорта
CPU usage

Для отображения расписания:
Время рендеринга страницы
Количество SQL запросов
Время выполнения SQL запросов

Для контроля корректности работы скрипта после внесения изменений, я сначала создал тест (spec/services/reloader_spec.rb)

## Гарантия корректности
Для обеспечения корректности оптимизации:

Написан интеграционный тест, проверяющий идентичность отображения данных из example.json до и после оптимизации
Используются стандартные Rails-тесты для проверки моделей и контроллеров
Сравнение результатов рендеринга страницы до и после оптимизации

## Feedback-Loop
Построен быстрый цикл обратной связи:

Для импорта:
Подготовлены тестовые JSON файлы разного размера (small.json, medium.jsom, large.json)
Добавил lib/profilers/profile.rb (запуск через rails runner lib/profilers/profile.rb), который позволил мне оперативно оценивать изменение метрики.

Для отображения:
rack-mini-profiler для профилирования рендеринга
pg_hero

## Поиск точек роста
Использованы инструменты профилирования:

Для импорта:
ruby-prof для анализа hot spots
memory_profiler для отслеживания утечек памяти
stackprof для профилирования CPU

Для отображения:
rack-mini-profiler
bullet для выявления N+1 запросов
pghero для анализа производительности PostgreSQL

## Результаты оптимизации
(будут заполнены после выполнения оптимизации):

Время импорта large.json: X секунд
Время рендеринга страницы Самара-Москва: Y мс
Количество SQL запросов: уменьшено с Z до W
Этот case-study будет дополняться конкретными цифрами и деталями реализации по мере выполнения оптимизации.

### №1 Замена find_or_create_by на batch insert
- ruby-prof
- find_or_create_by создает отдельную транзакцию для каждого города.
- Использование Set для уникальных значений и batch insert существенно снизило количество запросов к БД

### №2 Замена find_or_create_by на batch insert
- ruby-prof
- Каждый update создавал новую транзакцию и требовал загрузки связанных объектов
- Прямой SQL insert значительно эффективнее для массовой вставки

### №3 Предварительный сбор и подготовка данных
- memory_profiler показал высокое потребление памяти при создании объектов внутри цикла.
- Разделение процесса на сбор данных и их сохранение позволило эффективнее использовать память.

## Итого:
Время выполнения для small.json  уменьшилось с 27 секунд до 0.3 секунд.
Время выполнения для large.json составила 12 секунд, что укладывается в бюджет.
